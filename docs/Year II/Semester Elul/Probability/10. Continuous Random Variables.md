> [!warning] Warning!
> There be calculus within these pages. Yaarrrrghh!
### Probability Density Function
##### Definition
If X is a continuous random variable, then X can assume any value within some *interval* *(e.g. $(1,4)$, $(-\infty,\pi)$, etc)* rather than a set of discrete values.
In this situation, $P_X(z)=0\mid\forall z\in\Bbb R$, because an interval contains infinitely many points.
We can only speak of probabilities of X lying in some subinterval: $P(a<X<b)$, $P(X<b)$, $P(X>a)$

We use the <u>probability density function</u> of $X$, denoted $f_X$, to calculate the probabilities of $X$ falling in any given interval.

How do we do this?
> [!example]
> Suppose $X\in(1,6)$, and $X$’s probability density function looks like this.
> For the sake of example, let’s say we are looking for $P(3<X<4)$. This value can be found by calculating the *area under the graph* in that given interval.
> ![[10. Continuous Random Variables 2023-09-12-14.48.54.excalidraw]]
> Applying principles [[06. Definite Integrals|from calculus]], we know that the area is equal to $\int_3^4f_X(t)dt$

##### Properties of Probability Density Functions
1. $f_X≥0$ always
2. The total area under the graph of $f_X$ is 1
	- $\int_{-\infty}^\infty f_X(t)dt=1$

$f_X$ has the property, for any $a,b\in\Bbb R$:

$$P(a<X<b)=\int_a^bf_X(t)dt$$

> [!example] Is $f_X$ a density function?
> $f_X(x)=\begin{cases}\frac34(2x-x^2)&0<x<2\\0&otherwise\end{cases}$
> 
> ![[10. Continuous Random Variables 2023-09-12-15.04.54.excalidraw]]
> 
> Is this a density function?
> 
> 1. $f_x≥0$ always
> 	- Yes 
> 2. $\int_{-\infty}^\infty f_x(t)dt=1$
> 	- $\int_{-\infty}^\infty f_x(t)dt=\int_{0}^2 \frac34(2x-x^2)dx=\frac34(x^2-\frac{x^3}3)\Bigr|_0^2=\frac34(4-\frac83)=1$
> 	- Yes
> 
> $f_X$ is a density function.

Find $P(1<X,\frac23)$

### Cumulative Distribution Function
##### Definition
The <u>cumulative distribution function</u> $F_X$ (of a continuous random variable X) is defined as:

$$F_X(a)=\int_{-\infty}^af(t)dt$$

This is the area under the graph *up to* $a$.
By no coincidence, this is also $P(X<a)$

This function is useful because $P(a<X<b)=F_X(b)-F_X(a)$.
It saves us from having to repeatedly calculate integrals at every step, by doing it once at the beginning.

> [!example] Continuing from previous example
> 
> $f_X(x)=\begin{cases}\frac34(2x-x^2)&0<x<2\\0&otherwise\end{cases}$
> $F_X(x)=\begin{cases}0&x<0\\\int_0^x\frac34(2t-t^2)dt&0<x<2\\1&x>2\end{cases}$
> That’s very nice and all, but we want to avoid repetitive integration, so we calculate it here:
>
> $$\int_0^x\frac34(2t-t^2)dt=\frac34(x^2-\frac{x^3}3)$$
>
> Our final cumulative distribution function looks like this:
> 
> $$F_X(x)=\begin{cases}0&x<0\\\frac34(x^2-\frac{x^3}3)&0<x<2\\1&x>2\end{cases}$$
>
> ---
> So if we want to find $P(1<X<\frac23)$, all we need to do is $F_X(\frac23)-F_X(1)$
> 
> $$F_X(\frac23)-F_X(1)=\frac34\left(\frac94-\frac{27}{29}\right)-\frac34\left(\frac23\right)\approx0.489$$


 #### Properties of $F_X(x)$
 1. $F$ is always increasing
 2. $\lim_{x\to\infty}F(x)=1$
	 - $\lim_{x\to-\infty}F(x)=0$
 - $F$ is always continuous, even if $f$ isn’t!

### Expected Value of Continuous Random Variables

$$E[X]=\int_{-\infty}^\infty x\cdot f(x)dx$$

#### Properties of Expected Values
All the properties carry over from the [[05. Expected Values#Properties of Expected Values|Expected Value of discrete random variables]].
$E\left[g(X)\right]=\int_{-\infty}^\infty g(x)\cdot f(x)dx$


### Variance of Continuous Random Variables
Variance is defined the same way as for [[06. Variance#Formula|discrete random variables]]:

$$V(X)=E\left[X^2\right]-\mu^2$$

As [[06. Variance#Standard Deviation|with discrete random variables]],

$$\sigma(X)=\sqrt{V(X)}$$

All properties of $V$ and $\sigma$ carry also apply to continuous random variables.