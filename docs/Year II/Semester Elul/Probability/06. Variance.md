##### Definition
The <u>variance</u> of a random variable $X$ is a measure of how far $X$ can (and will) differ from its expected value.
(i.e., $V(X)$ measures the “spread” of possible values of $X$.)

###### Formula
$$V(X)=E[X^2]-E[X]^2$$

> [!example] 
> Define $X_1, X_2$ using the following probability functions:
> 
> 
> |$k_1$|$P_{X_1}(k_1)$|$\mid$|$k_2$|$P_{X_2}(k_2)$|
> -:|:-|:-:|-:|:-
> 5|$\frac13$|$\mid$|0|$\frac13$
> 10|$\frac13$|$\mid$|10|$\frac13$
> 15|$\frac13$|$\mid$|20|$\frac13$
> 
> $E[X_1]=\frac{5+10+15}{3} = 10$
> $E[X_2]=\frac{0 + 10 +20}{3} = 10$
> They both have the same expected value, but $V(X_2)$ should be greater than $V(X_1)$ because the values are more spread out from their Expected Values
> $V(X_1)=\frac13(5^2+0^2+5^2)=\frac{50}3=16\frac23$
> $V(X_2)=\frac13(10^2+0^2+10^2)=\frac{200}3=66\frac23$

### Properties
1. Formula: $V(X)=E[X^2]-E[X]^2$
2. For any $c\in\Bbb R$: $V(cX)=c^2\cdot V(X)$
3. For any $c\in\Bbb R$: $V(X+3)=V(X)$
	- Intuition: the spread of a r.v. is unaffected when we merely “shift” all of it’s possible values by a constant $c$
	- This is tightly related to [[05. Expected Values#Properties of Expected Values|property 2 of Expected Values]] $E[X+c]=E[X]+c$

## Standard Deviation
##### Definition
$$\sigma(X)=\sqrt{V(X)}$$
> [!tip] Intuition
> Variance “magnifies” the difference $E[X^2]-E[X]^2$ by squaring it, so $\sigma(X)$ neutralizes this magnification

Note: As a square root, $\sigma(X) \ge 0$ **always**.

### Properties
1. $\sigma(cX)=|c|\cdot\sigma(X)\mid\forall c\in\Bbb R$
2. $\sigma(X+c)=\sigma(X)$